{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HeroBenHero/HeroColabs/blob/main/IEEE_Downloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "OJhLoXYX3SE0"
      },
      "outputs": [],
      "source": [
        "#@markdown **Pre-Requisites**\n",
        "import os\n",
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QeswvRARq3Uz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "742f7f29-1499-4ac2-e4b9-9c5f5faa3137"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "No PDF file found on the webpage.\n"
          ]
        }
      ],
      "source": [
        "#@markdown **Enter The IEEE Link To Download The Paper**\n",
        "Site = \"https://sci-hub.gupiaoq.com/\" #@param {type:\"string\"}\n",
        "Link = \"https://ieeexplore.ieee.org/document/8987242/\" #@param {type:\"string\"}\n",
        "\n",
        "# Step 1: Fetch the HTML content of the webpage\n",
        "url = Site+Link\n",
        "response = requests.get(url)\n",
        "\n",
        "# Step 2: Extract the URL of the embedded PDF\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "download_button = soup.find('button')\n",
        "print()\n",
        "if download_button:\n",
        "    onclick_attr = download_button['onclick']\n",
        "    pdf_url = 'https://'+onclick_attr.split('=')[1].replace(\"'\", \"\").lstrip('/')\n",
        "    if 'tree/' in pdf_url:\n",
        "      print(\"Visit\",Site,\"And Download Mannually\")\n",
        "    elif 'downloads/' in pdf_url:\n",
        "      print('No PDF file found on the webpage.')\n",
        "    else:\n",
        "      print(\"Your Paper Download Link Is :\\n\",pdf_url)\n",
        "else:\n",
        "    print('No PDF file found on the webpage.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Wu5Rs3iaCagX"
      },
      "outputs": [],
      "source": [
        "#@markdown **Enter The IEEE Search Result Source Code To Extract The Paper Links**\n",
        "# Example string\n",
        "Source = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# Regular expression to match '/document/(integer)/'\n",
        "pattern = r'/document/(\\d+)/'\n",
        "\n",
        "# Extract all occurrences of the pattern\n",
        "matches = list(set(re.findall(pattern, Source)))\n",
        "\n",
        "# Append prefix to each match\n",
        "matches = [f'https://ieeexplore.ieee.org/document/{match}/' for match in matches]\n",
        "\n",
        "# Print the matches\n",
        "for match in matches:\n",
        "    print(match)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AqlKXkMPER6O"
      },
      "outputs": [],
      "source": [
        "#@markdown **Enter The IEEE Search Result Source Code To Extract The Paper Download Links**\n",
        "\n",
        "def listpdf(Link):\n",
        "\n",
        "  Site = \"https://sci-hub.gupiaoq.com/\" #@param {type:\"string\"}\n",
        "\n",
        "  # Step 1: Fetch the HTML content of the webpage\n",
        "  url = Site+Link\n",
        "  response = requests.get(url)\n",
        "\n",
        "  # Step 2: Extract the URL of the embedded PDF\n",
        "  soup = BeautifulSoup(response.content, 'html.parser')\n",
        "  download_button = soup.find('button')\n",
        "  if download_button:\n",
        "      onclick_attr = download_button['onclick']\n",
        "      pdf_url = 'https://'+onclick_attr.split('=')[1].replace(\"'\", \"\").lstrip('/')\n",
        "      if 'downloads/' not in pdf_url:\n",
        "        # if 'downloads/' or 'tree/' not in pdf_url:\n",
        "        # print(Link)\n",
        "        print(pdf_url)\n",
        "  #     else:\n",
        "  #       print('No PDF file found on the webpage.')\n",
        "  #     #!wget {pdf_url}\n",
        "  # else:\n",
        "  #     print('No PDF file found on the webpage.')\n",
        "\n",
        "# Example string\n",
        "# Source = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# # Regular expression to match '/document/(integer)/'\n",
        "# pattern = r'/document/(\\d+)/'\n",
        "\n",
        "# # Extract all occurrences of the pattern\n",
        "# matches = list(set(re.findall(pattern, Source)))\n",
        "\n",
        "# # Append prefix to each match\n",
        "# matches = [f'https://ieeexplore.ieee.org/document/{match}/' for match in matches]\n",
        "\n",
        "# # Print the matches\n",
        "# for match in matches:\n",
        "#     listpdf(match)\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "# Example string\n",
        "source = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# Parse the webpage using Beautiful Soup\n",
        "soup = BeautifulSoup(source, 'html.parser')\n",
        "\n",
        "# Find all links with the desired URL in their href attribute\n",
        "links = soup.find_all('a', href=lambda href: href and '/document/' in href and 'citations?' not in href)\n",
        "\n",
        "# Print the links\n",
        "for link in set(links):\n",
        "    link='https://ieeexplore.ieee.org'+link['href']\n",
        "    # print(link)\n",
        "    listpdf(link)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **Enter The IEEE Search Result Source Code To Download The Paper**\n",
        "\n",
        "def download_pdf(Link,name):\n",
        "    Site = \"https://sci-hub.gupiaoq.com/\"  # @param {type:\"string\"}\n",
        "\n",
        "    # Step 1: Fetch the HTML content of the webpage\n",
        "    url = Site + Link\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Step 2: Extract the URL of the embedded PDF\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    download_button = soup.find('button')\n",
        "    if download_button:\n",
        "        onclick_attr = download_button['onclick']\n",
        "        pdf_url = 'https://' + onclick_attr.split('=')[1].replace(\"'\", \"\").lstrip('/')\n",
        "        if 'downloads/' not in pdf_url:\n",
        "            # Step 3: Download the PDF\n",
        "            pdf_response = requests.get(pdf_url)\n",
        "            with open(name+'.pdf', 'wb') as f:\n",
        "                f.write(pdf_response.content)\n",
        "            print(\"PDF downloaded successfully.\",Link)\n",
        "\n",
        "  #     else:\n",
        "  #       print('No PDF file found on the webpage.')\n",
        "  #     #!wget {pdf_url}\n",
        "  # else:\n",
        "  #     print('No PDF file found on the webpage.')\n",
        "\n",
        "# Example string\n",
        "# Source = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# # Regular expression to match '/document/(integer)/'\n",
        "# pattern = r'/document/(\\d+)/'\n",
        "\n",
        "# # Extract all occurrences of the pattern\n",
        "# matches = list(set(re.findall(pattern, Source)))\n",
        "\n",
        "# # Append prefix to each match\n",
        "# matches = [f'https://ieeexplore.ieee.org/document/{match}/' for match in matches]\n",
        "\n",
        "# # Print the matches\n",
        "# for match in matches:\n",
        "#     listpdf(match)\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "# Example string\n",
        "source = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# Parse the webpage using Beautiful Soup\n",
        "soup = BeautifulSoup(source, 'html.parser')\n",
        "\n",
        "# Find all links with the desired URL in their href attribute\n",
        "links = soup.find_all('a', href=lambda href: href and '/document/' in href and 'citations?' not in href)\n",
        "\n",
        "# Print the links\n",
        "for link in set(links):\n",
        "    ieee_link='https://ieeexplore.ieee.org'+link['href']\n",
        "    # print(link)\n",
        "    download_pdf(ieee_link,link['href'].replace(\"/document/\",'').replace('/',''))\n",
        ""
      ],
      "metadata": {
        "cellView": "form",
        "id": "FdcqUwM56w77"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJrfqEMLKAnbjoWgiqWdGI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}